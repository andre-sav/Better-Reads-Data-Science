{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('book_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54301, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_authors</th>\n",
       "      <th>book_desc</th>\n",
       "      <th>book_edition</th>\n",
       "      <th>book_format</th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>book_pages</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_rating_count</th>\n",
       "      <th>book_review_count</th>\n",
       "      <th>book_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54296</th>\n",
       "      <td>Howard Megdal</td>\n",
       "      <td>In this fearless and half-crazy story, Howard ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78161E+12</td>\n",
       "      <td>256 pages</td>\n",
       "      <td>3.37</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>Taking the Field: A Fan's Quest to Run the Tea...</td>\n",
       "      <td>Sports|Baseball|Sports and Games|Sports|Nonfic...</td>\n",
       "      <td>https://images.gr-assets.com/books/1312074392l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54297</th>\n",
       "      <td>Howard Megdal</td>\n",
       "      <td>From the icons of the game to the players who ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78006E+12</td>\n",
       "      <td>256 pages</td>\n",
       "      <td>3.97</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>The Baseball Talmud: Koufax, Greenberg, and th...</td>\n",
       "      <td>Nonfiction|Sports and Games|Sports</td>\n",
       "      <td>https://images.gr-assets.com/books/1348841629l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54298</th>\n",
       "      <td>Howard Megdal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kindle Edition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.66</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilpon's Folly - The Story of a Man, His Fortu...</td>\n",
       "      <td>Sports|Baseball|Abandoned</td>\n",
       "      <td>https://images.gr-assets.com/books/1394277097l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54299</th>\n",
       "      <td>Mimi Baird|Eve Claxton</td>\n",
       "      <td>Soon to be a major motion picture, from Brad P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.7808E+12</td>\n",
       "      <td>272 pages</td>\n",
       "      <td>3.82</td>\n",
       "      <td>867</td>\n",
       "      <td>187</td>\n",
       "      <td>He Wanted the Moon: The Madness and Medical Ge...</td>\n",
       "      <td>Nonfiction|Autobiography|Memoir|Biography|Psyc...</td>\n",
       "      <td>https://images.gr-assets.com/books/1403192135l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54300</th>\n",
       "      <td>Leah Price</td>\n",
       "      <td>The Anthology and the Rise of the Novel brings...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9.78052E+12</td>\n",
       "      <td>236 pages</td>\n",
       "      <td>3.58</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>The Anthology and the Rise of the Novel: From ...</td>\n",
       "      <td>Criticism|Literary Criticism|Philosophy|Theory...</td>\n",
       "      <td>https://images.gr-assets.com/books/1349014225l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 book_authors  \\\n",
       "54296           Howard Megdal   \n",
       "54297           Howard Megdal   \n",
       "54298           Howard Megdal   \n",
       "54299  Mimi Baird|Eve Claxton   \n",
       "54300              Leah Price   \n",
       "\n",
       "                                               book_desc book_edition  \\\n",
       "54296  In this fearless and half-crazy story, Howard ...          NaN   \n",
       "54297  From the icons of the game to the players who ...          NaN   \n",
       "54298                                                NaN          NaN   \n",
       "54299  Soon to be a major motion picture, from Brad P...          NaN   \n",
       "54300  The Anthology and the Rise of the Novel brings...          NaN   \n",
       "\n",
       "          book_format    book_isbn book_pages  book_rating  book_rating_count  \\\n",
       "54296       Hardcover  9.78161E+12  256 pages         3.37                 27   \n",
       "54297       Hardcover  9.78006E+12  256 pages         3.97                 34   \n",
       "54298  Kindle Edition          NaN        NaN         3.66                 32   \n",
       "54299       Hardcover   9.7808E+12  272 pages         3.82                867   \n",
       "54300       Paperback  9.78052E+12  236 pages         3.58                 12   \n",
       "\n",
       "       book_review_count                                         book_title  \\\n",
       "54296                  9  Taking the Field: A Fan's Quest to Run the Tea...   \n",
       "54297                  5  The Baseball Talmud: Koufax, Greenberg, and th...   \n",
       "54298                  3  Wilpon's Folly - The Story of a Man, His Fortu...   \n",
       "54299                187  He Wanted the Moon: The Madness and Medical Ge...   \n",
       "54300                  3  The Anthology and the Rise of the Novel: From ...   \n",
       "\n",
       "                                                  genres  \\\n",
       "54296  Sports|Baseball|Sports and Games|Sports|Nonfic...   \n",
       "54297                 Nonfiction|Sports and Games|Sports   \n",
       "54298                          Sports|Baseball|Abandoned   \n",
       "54299  Nonfiction|Autobiography|Memoir|Biography|Psyc...   \n",
       "54300  Criticism|Literary Criticism|Philosophy|Theory...   \n",
       "\n",
       "                                               image_url  \n",
       "54296  https://images.gr-assets.com/books/1312074392l...  \n",
       "54297  https://images.gr-assets.com/books/1348841629l...  \n",
       "54298  https://images.gr-assets.com/books/1394277097l...  \n",
       "54299  https://images.gr-assets.com/books/1403192135l...  \n",
       "54300  https://images.gr-assets.com/books/1349014225l...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_rating_count</th>\n",
       "      <th>book_review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54301.000000</td>\n",
       "      <td>5.430100e+04</td>\n",
       "      <td>54301.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.020027</td>\n",
       "      <td>4.350449e+04</td>\n",
       "      <td>2011.60218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.362100</td>\n",
       "      <td>2.126572e+05</td>\n",
       "      <td>7627.07287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.830000</td>\n",
       "      <td>4.070000e+02</td>\n",
       "      <td>35.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.030000</td>\n",
       "      <td>2.811000e+03</td>\n",
       "      <td>188.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.220000</td>\n",
       "      <td>1.274500e+04</td>\n",
       "      <td>822.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.588580e+06</td>\n",
       "      <td>160776.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        book_rating  book_rating_count  book_review_count\n",
       "count  54301.000000       5.430100e+04        54301.00000\n",
       "mean       4.020027       4.350449e+04         2011.60218\n",
       "std        0.362100       2.126572e+05         7627.07287\n",
       "min        0.000000       0.000000e+00            0.00000\n",
       "25%        3.830000       4.070000e+02           35.00000\n",
       "50%        4.030000       2.811000e+03          188.00000\n",
       "75%        4.220000       1.274500e+04          822.00000\n",
       "max        5.000000       5.588580e+06       160776.00000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminating duplicates and rows with no book ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['book_rating_count'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_authors             0\n",
       "book_desc             1317\n",
       "book_edition         48779\n",
       "book_format           1649\n",
       "book_isbn            12829\n",
       "book_pages            2495\n",
       "book_rating              0\n",
       "book_rating_count        0\n",
       "book_review_count        0\n",
       "book_title               0\n",
       "genres                3170\n",
       "image_url              663\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54226, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48412, 12)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset =\"book_title\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46712, 12)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset =\"book_desc\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_authors             0\n",
       "book_desc                1\n",
       "book_edition         42204\n",
       "book_format           1222\n",
       "book_isbn            10339\n",
       "book_pages            1891\n",
       "book_rating              0\n",
       "book_rating_count        0\n",
       "book_review_count        0\n",
       "book_title               0\n",
       "genres                2625\n",
       "image_url              377\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use book description as sole feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46712, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['book_authors','book_desc','book_title']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46711, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate observations with non-English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_english(text):\n",
    "    english = ' '.join([w for w in text.split() if wordnet.synsets(w)])\n",
    "    return english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: make_english(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_words'] = df['book_desc'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['num_words'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_authors    0\n",
       "book_desc       0\n",
       "book_title      0\n",
       "num_words       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44548, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['book_authors','book_desc','book_title']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate punctuation, numbers and capital letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = re.sub('<.*?>', '', text)   # remove HTML tags\n",
    "    new_text = re.sub(\"[!@#$+%*:()'-]\",'',new_text) # remove punc.\n",
    "    new_text = re.sub(r'\\d+','',new_text)# remove numbers\n",
    "    new_text = new_text.lower() # lower case, .upper() for upper\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use lemmatizer and join result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: word_lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stemmer(text):\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in text])\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: word_stemmer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize and use cosine similarity to get top 5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = np.array(df['book_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create preprocessor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    new_text = re.sub('<.*?>', '', text)   # remove HTML tags\n",
    "    new_text = re.sub(\"[!@#$+%*:()'-]\",'',new_text) # remove punc.\n",
    "    new_text = re.sub(r'\\d+','',new_text)# remove numbers\n",
    "    new_text = new_text.lower() # lower case, .upper() for upper\n",
    "    tokenized_text = tokenizer.tokenize(new_text)\n",
    "    words = [w for w in tokenized_text if w not in stopwords.words('english')]\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in words]\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in lem_text])\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'could surviv wild everyon make sure dont live see morn ruin place known north america lie nation panem shine capitol surround twelv outli district capitol harsh cruel keep district line forc send one boy one girl age twelv eighteen particip annual hunger game fight death live tv sixteenyearold katniss everdeen life alon mother younger sister regard death sentenc forc repres district game katniss close dead surviv second natur without realli mean becom contend win start make choic weigh surviv human life love new york time bestsel author suzann collin deliv equal part suspens philosophi adventur romanc sear novel set futur unsettl parallel present'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor('Could you survive on your own, in the wild, with everyone out to make sure you dont live to see the morning? In the ruins of a place once known as North America lies the nation of Panem, a shining Capitol surrounded by twelve outlying districts. The Capitol is harsh and cruel and keeps the districts in line by forcing them all to send one boy and one girl between the ages of twelve and eighteen to participate in the annual Hunger Games, a fight to the death on live TV. Sixteen-year-old Katniss Everdeen, who lives alone with her mother and younger sister, regards it as a death sentence when she is forced to represent her district in the Games. But Katniss has been close to dead before - and survival, for her, is second nature. Without really meaning to, she becomes a contender. But if she is to win, she will have to start making choices that weigh survival against humanity and life against love. New York Times bestselling author Suzanne Collins delivers equal parts suspense and philosophy, adventure and romance, in this searing novel set in a future with unsettling parallels to our present.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create predictions function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "    documents = [preprocessor(text)]\n",
    "    tfidf_matrix_new = tfidf_vectorizer.transform(documents)\n",
    "    array = cosine_similarity(tfidf_matrix_new, tfidf_matrix)[0]\n",
    "    recommender = df.copy()\n",
    "    recommender['cs'] = array\n",
    "    recommender.sort_values(by=['cs'], ascending=False)\n",
    "    return recommender.nlargest(5, 'cs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_authors</th>\n",
       "      <th>book_desc</th>\n",
       "      <th>book_title</th>\n",
       "      <th>cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21738</th>\n",
       "      <td>Mary Roach</td>\n",
       "      <td>bestsel author stiff bonk explor irresist stra...</td>\n",
       "      <td>Packing for Mars: The Curious Science of Life ...</td>\n",
       "      <td>0.413578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>Carl Sagan|Ann Druyan</td>\n",
       "      <td>pulitz author trace explor space suggest survi...</td>\n",
       "      <td>Pale Blue Dot: A Vision of the Human Future in...</td>\n",
       "      <td>0.410082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38964</th>\n",
       "      <td>Piers Bizony</td>\n",
       "      <td>boldli go book gone explor come realiti person...</td>\n",
       "      <td>How To Build Your Own Spaceship: The Science O...</td>\n",
       "      <td>0.313127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53172</th>\n",
       "      <td>David Hitt|Owen  Garriott|Joe Kerwin</td>\n",
       "      <td>unit state soviet union went explor space live...</td>\n",
       "      <td>Homesteading Space: The Skylab Story</td>\n",
       "      <td>0.294092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34648</th>\n",
       "      <td>Jon Butterworth</td>\n",
       "      <td>discoveri boson made headlin around two peter ...</td>\n",
       "      <td>Smashing Physics</td>\n",
       "      <td>0.283299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               book_authors  \\\n",
       "21738                            Mary Roach   \n",
       "2028                  Carl Sagan|Ann Druyan   \n",
       "38964                          Piers Bizony   \n",
       "53172  David Hitt|Owen  Garriott|Joe Kerwin   \n",
       "34648                       Jon Butterworth   \n",
       "\n",
       "                                               book_desc  \\\n",
       "21738  bestsel author stiff bonk explor irresist stra...   \n",
       "2028   pulitz author trace explor space suggest survi...   \n",
       "38964  boldli go book gone explor come realiti person...   \n",
       "53172  unit state soviet union went explor space live...   \n",
       "34648  discoveri boson made headlin around two peter ...   \n",
       "\n",
       "                                              book_title        cs  \n",
       "21738  Packing for Mars: The Curious Science of Life ...  0.413578  \n",
       "2028   Pale Blue Dot: A Vision of the Human Future in...  0.410082  \n",
       "38964  How To Build Your Own Spaceship: The Science O...  0.313127  \n",
       "53172               Homesteading Space: The Skylab Story  0.294092  \n",
       "34648                                   Smashing Physics  0.283299  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions('I want to read a book about scientific discoveries and space exploration')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
